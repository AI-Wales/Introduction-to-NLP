{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing common and unwanted words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have tidied up our text and split it into smaller chunks. But to start to process it there are a number of further tasks we might want to do. For statistical analysis we might want to remove many of the joining and most used words as these may skew results.\n",
    "\n",
    "These words are often called Stopwords. You can create your own lost based on the the text you have or use standard lists that you can add/alter to suit your needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'did', 'it', 'of', 'are', 'and', 'on','' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_o=\"\"\"\n",
    "First time, I did it for the hell of it \n",
    "Stuck it on the back of my tongue \n",
    "And swallowed it \n",
    "Second time, things are\n",
    "Getting easier \n",
    "Blow me down this wind\n",
    "Is getting breezier \n",
    "Third time lucky, maybe feelin' fuzzy \n",
    "Oh my God! we're getting hippy-dippy!\n",
    "5-6-7 man I'm in heaven \n",
    "And I'm growing my beard \n",
    "Until it gets sheared\n",
    "You're on my mind \n",
    "Every day and every night \n",
    "And you'll never go away \n",
    "Cause I know you're here to stay \n",
    "For the rest of my mind\n",
    "I just keep repeating myself\n",
    "I just keep repeating myself\n",
    "I just keep repeating myself\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First', 'time', 'I', 'for', 'hell', 'Stuck', 'back', 'my', 'tongue', 'And', 'swallowed', 'Second', 'time', 'things', 'Getting', 'easier', 'Blow', 'me', 'down', 'this', 'wind', 'Is', 'getting', 'breezier', 'Third', 'time', 'lucky', 'maybe', 'feelin', 'fuzzy', 'Oh', 'my', 'God!', 'were', 'getting', 'hippy-dippy!', '5-6-7', 'man', 'Im', 'in', 'heaven', 'And', 'Im', 'growing', 'my', 'beard', 'Until', 'gets', 'sheared', 'Youre', 'my', 'mind', 'Every', 'day', 'every', 'night', 'And', 'youll', 'never', 'go', 'away', 'Cause', 'I', 'know', 'youre', 'here', 'to', 'stay', 'For', 'rest', 'my', 'mind', 'I', 'just', 'keep', 'repeating', 'myself', 'I', 'just', 'keep', 'repeating', 'myself', 'I', 'just', 'keep', 'repeating', 'myself']\n"
     ]
    }
   ],
   "source": [
    "#process the text \n",
    "import re\n",
    "\n",
    "text_processed = re.sub(r'[.,?:\\']', \"\", text_o)\n",
    "textn = re.sub(r'\\n', \" \", text_processed)\n",
    "text_processed = re.sub( r'  +', \" \", text_processed)\n",
    "tokens = textn.split(\" \")\n",
    "\n",
    "# remove stopwords\n",
    "\n",
    "tokens_sw = [t for t in tokens if t not in stopwords]\n",
    "print(tokens_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you see any issue swith the processed text? What other pre-processing would you do? Are there any symbols or digits you'd think about removing? How would you do this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
