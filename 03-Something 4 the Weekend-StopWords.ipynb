{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing common and unwanted words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have tidied up our text and split it into smaller chunks. But to start to process it there are a number of further tasks we might want to do. For statistical analysis we might want to remove many of the joining and most used words as these may skew results.\n",
    "\n",
    "These words are often called **Stopwords**. You can create your own list of stopwords based on the the text you have or use standard lists that you can add/alter to suit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_o=\"\"\"\n",
    "First time, I did it for the hell of it \n",
    "Stuck it on the back of my tongue \n",
    "And swallowed it \n",
    "Second time, things are\n",
    "Getting easier \n",
    "Blow me down this wind\n",
    "Is getting breezier \n",
    "Third time lucky, maybe feelin' fuzzy \n",
    "Oh my God! we're getting hippy-dippy!\n",
    "5-6-7 man I'm in heaven \n",
    "And I'm growing my beard \n",
    "Until it gets sheared\n",
    "You're on my mind \n",
    "Every day and every night \n",
    "And you'll never go away \n",
    "Cause I know you're here to stay \n",
    "For the rest of my mind\n",
    "I just keep repeating myself\n",
    "I just keep repeating myself\n",
    "I just keep repeating myself\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Stopword List\n",
    "\n",
    "Simply create a list with each word in it. Then clean up and word tokenise the text, then remove any tokens that are in the list using a list comprehension. \n",
    "\n",
    "Firstly define the stopword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'did', 'it', 'of', 'are', 'and', 'on','' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then preprocess the text and check against the stopword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First', 'time', 'I', 'for', 'hell', 'Stuck', 'back', 'my', 'tongue', 'And', 'swallowed', 'Second', 'time', 'things', 'Getting', 'easier', 'Blow', 'me', 'down', 'this', 'wind', 'Is', 'getting', 'breezier', 'Third', 'time', 'lucky', 'maybe', 'feelin', 'fuzzy', 'Oh', 'my', 'God!', 'were', 'getting', 'hippy-dippy!', '5-6-7', 'man', 'Im', 'in', 'heaven', 'And', 'Im', 'growing', 'my', 'beard', 'Until', 'gets', 'sheared', 'Youre', 'my', 'mind', 'Every', 'day', 'every', 'night', 'And', 'youll', 'never', 'go', 'away', 'Cause', 'I', 'know', 'youre', 'here', 'to', 'stay', 'For', 'rest', 'my', 'mind', 'I', 'just', 'keep', 'repeating', 'myself', 'I', 'just', 'keep', 'repeating', 'myself', 'I', 'just', 'keep', 'repeating', 'myself']\n"
     ]
    }
   ],
   "source": [
    "#process the text \n",
    "import re\n",
    "\n",
    "text_processed = re.sub(r'[.,?:\\']', \"\", text_o)\n",
    "text_processed = re.sub(r'\\n', \" \", text_processed)\n",
    "text_processed = re.sub( r'  +', \" \", text_processed)\n",
    "tokens = text_processed.split(\" \")\n",
    "\n",
    "# remove stopwords\n",
    "\n",
    "tokens_sw = [t for t in tokens if t not in stopwords]\n",
    "print(tokens_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you see any issues with the processed text? \n",
    "#### What other pre-processing would you do? \n",
    "#### Are there any symbols or digits you'd think about removing? \n",
    "#### How would you do this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try your ideas here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
