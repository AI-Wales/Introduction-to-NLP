{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using spaCy to pre-process and analysis text\n",
    "\n",
    "We have already looked at NLTK, but other NLP libraries and packages are available. Here are the most common:\n",
    "\n",
    "1. [NLTK](https://www.nltk.org) for text processing\n",
    "2. [spaCy](https://spacy.io) for fast text processing\n",
    "3. [Gensim](https://radimrehurek.com/gensim/) For topic modelling \n",
    "4. [SciKit Learn](http://scikit-learn.org/stable/) For clustering and topic modelling \n",
    "\n",
    "For the rest of these notebooks we will use spaCy. All of these packages have their place and you may end up using tools from all of them if you are building a text processing pipeline. We will deonmstrate spaCy as it allows us to show the basics but also get an insight into some of the more interesting and useful aspects of nlp (which are for another session!).\n",
    "\n",
    "We will use the default spaCy model and see how it processes text by examining its outputs. We will also develop our own pipleine to use in spaCy. \n",
    "\n",
    "Before you start make sure you have installed spaCy and the en model:\n",
    "<br>\n",
    "```conda install -c conda-forge spacy```\n",
    "<br>\n",
    "```python -m spacy download en```\n",
    "<br>\n",
    "\n",
    "See the [spaCy](https://spacy.io) documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "I was lost,\n",
    "lost on the bypass road.\n",
    "Could be worse,\n",
    "I could be turned to toad.\n",
    "Won't you take me back to my hometown?\n",
    "Take me back before I break down.\n",
    "I say you please return me,\n",
    "Will you ever return me?\n",
    "Will you ever return me?\n",
    "Just like Frankie Fontaine\n",
    "Just like Frankie Fontaine\n",
    "I wonder what can I do?\n",
    "I was found\n",
    "riding a unicorn.\n",
    "Could be worse,\n",
    "I could be backwards born\n",
    "Won't you take me back to my hometown?\n",
    "Take me back before I break down.\n",
    "Will you ever return me?\n",
    "Will you ever return me?\n",
    "Will you ever return me?\n",
    "Just like Frankie Fontaine\n",
    "I say you please return me\n",
    "Will you ever return me?\n",
    "Will you ever return me?\n",
    "Just like Frankie Fontaine\n",
    "I wonder what can I do?\n",
    "calm down and then leave me alone\n",
    "calm down and then leave me alone \n",
    "calm down and then leave me alone \n",
    "calm down and then leave me alone\n",
    "I say you please return me\n",
    "Will you ever return me?\n",
    "Will you ever return me?\n",
    "Just like Frankie Fontaine\n",
    "Just like Frankie Fontaine\n",
    "I wonder what can I do?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the spaCy english model and applying it to our text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the outputs\n",
    "spaCy has performed a lot of processing on the text. This includes: \n",
    "\n",
    "* Tokenisation - Segmenting text into words, punctuations marks etc.\n",
    "* Part-of-Speech (POS) tagging - Assigning word types to tokens, like verb or noun.\n",
    "* Dependency Parsing - Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\n",
    "* Lemmatization - Assigning the base forms of words. For example, the lemma of \"was\" is \"be\", and the lemma of \"rats\" is \"rat\".\n",
    "* Sentence Boundary Detection (SBD) - Finding and segmenting individual sentences.\n",
    "* Named Entity Recognition (NER) - Labelling named \"real-world\" objects, like persons, companies or locations.\n",
    "* Similarity - Comparing words, text spans and documents and how similar they are to each other.\n",
    "* Text Classification - Assigning categories or labels to a whole document, or parts of a document.\n",
    "* Rule-based Matching - Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\n",
    "\n",
    "Lets have a look at some of these and how we can use them.\n",
    "\n",
    "### Tokenisation\n",
    "spaCy has split the text into indiviudal tokens, preserving punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'I', 'was', 'lost', '\\n', 'Lost', 'on', 'the', 'bypass', 'road', '\\n', 'Could', 'be', 'worse', '\\n', 'I', 'could', 'be', 'turned', 'to', 'toad', '\\n', 'Wo', \"n't\", 'you', 'take', 'me', 'back', 'to', 'my', 'hometown', '?', '\\n', 'Take', 'me', 'back', 'before', 'I', 'break', 'down', '\\n', 'I', 'say', 'you', 'please', 'return', 'me', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Just', 'like', 'Frankie', 'Fontaine', '\\n', 'Just', 'like', 'Frankie', 'Fontaine', '\\n', 'I', 'wonder', 'what', 'can', 'I', 'do', '?', '\\n', 'I', 'was', 'found', '\\n', 'Riding', 'a', 'unicorn', '\\n', 'Could', 'be', 'worse', '\\n', 'I', 'could', 'be', 'backwards', 'born', '\\n', 'Wo', \"n't\", 'you', 'take', 'me', 'back', 'to', 'my', 'hometown', '?', '\\n', 'Take', 'me', 'back', 'before', 'I', 'break', 'down', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Just', 'like', 'Frankie', 'Fontaine', '\\n', 'I', 'say', 'you', 'please', 'return', 'me', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Just', 'like', 'Frankie', 'Fontaine', '\\n', 'I', 'wonder', 'what', 'can', 'I', 'do', '?', '\\n', 'Calm', 'down', 'and', 'then', 'leave', 'me', 'alone', '\\n', 'Calm', 'down', 'and', 'then', 'leave', 'me', 'alone', '\\n', 'Calm', 'down', 'and', 'then', 'leave', 'me', 'alone', '\\n', 'Calm', 'down', 'and', 'then', 'leave', 'me', 'alone', '\\n', 'I', 'say', 'you', 'please', 'return', 'me', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Will', 'you', 'ever', 'return', 'me', '?', '\\n', 'Just', 'like', 'Frankie', 'Fontaine', '\\n', 'Just', 'like', 'Frankie', 'Fontaine', '\\n', 'I', 'wonder', 'what', 'can', 'I', 'do', '?', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation\n",
    "spaCy has also perfomed lemmatisation on the text. You can view these by looking atthe ```lemma_``` property rather that the ```text``` property of a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '-PRON-', 'be', 'lose', '\\n', 'lose', 'on', 'the', 'bypass', 'road', '\\n', 'could', 'be', 'bad', '\\n', '-PRON-', 'could', 'be', 'turn', 'to', 'toad', '\\n', 'will', 'not', '-PRON-', 'take', '-PRON-', 'back', 'to', '-PRON-', 'hometown', '?', '\\n', 'take', '-PRON-', 'back', 'before', '-PRON-', 'break', 'down', '\\n', '-PRON-', 'say', '-PRON-', 'please', 'return', '-PRON-', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'just', 'like', 'frankie', 'fontaine', '\\n', 'just', 'like', 'frankie', 'fontaine', '\\n', '-PRON-', 'wonder', 'what', 'can', '-PRON-', 'do', '?', '\\n', '-PRON-', 'be', 'find', '\\n', 'rid', 'a', 'unicorn', '\\n', 'could', 'be', 'bad', '\\n', '-PRON-', 'could', 'be', 'backwards', 'bear', '\\n', 'will', 'not', '-PRON-', 'take', '-PRON-', 'back', 'to', '-PRON-', 'hometown', '?', '\\n', 'take', '-PRON-', 'back', 'before', '-PRON-', 'break', 'down', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'just', 'like', 'frankie', 'fontaine', '\\n', '-PRON-', 'say', '-PRON-', 'please', 'return', '-PRON-', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'just', 'like', 'frankie', 'fontaine', '\\n', '-PRON-', 'wonder', 'what', 'can', '-PRON-', 'do', '?', '\\n', 'calm', 'down', 'and', 'then', 'leave', '-PRON-', 'alone', '\\n', 'calm', 'down', 'and', 'then', 'leave', '-PRON-', 'alone', '\\n', 'calm', 'down', 'and', 'then', 'leave', '-PRON-', 'alone', '\\n', 'calm', 'down', 'and', 'then', 'leave', '-PRON-', 'alone', '\\n', '-PRON-', 'say', '-PRON-', 'please', 'return', '-PRON-', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'will', '-PRON-', 'ever', 'return', '-PRON-', '?', '\\n', 'just', 'like', 'frankie', 'fontaine', '\\n', 'just', 'like', 'frankie', 'fontaine', '\\n', '-PRON-', 'wonder', 'what', 'can', '-PRON-', 'do', '?', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging\n",
    "\n",
    "spaCy has also tagged each token classifying if it is a digit, punctuation, etc. You can access these:\n",
    "\n",
    "* is_alpha\tbool\tDoes the token consist of alphabetic characters? Equivalent to token.text.isalpha().\n",
    "* is_ascii\tbool\tDoes the token consist of ASCII characters? Equivalent to [any(ord(c) >= 128 for c in token.text)].\n",
    "* is_digit\tbool\tDoes the token consist of digits? Equivalent to token.text.isdigit().\n",
    "* is_lower\tbool\tIs the token in lowercase? Equivalent to token.text.islower().\n",
    "* is_upper\tbool\tIs the token in uppercase? Equivalent to token.text.isupper().\n",
    "* is_title\tbool\tIs the token in titlecase? Equivalent to token.text.istitle().\n",
    "* is_punct\tbool\tIs the token punctuation?\n",
    "* is_left_punct\tbool\tIs the token a left punctuation mark, e.g. (?\n",
    "* is_right_punct\tbool\tIs the token a right punctuation mark, e.g. ]?\n",
    "* is_space\tbool\tDoes the token consist of whitespace characters? Equivalent to token.text.isspace().\n",
    "* is_bracket\tbool\tIs the token a bracket?\n",
    "* is_quote\tbool\tIs the token a quotation mark?\n",
    "* is_currency\tbool\tIs the token a currency symbol?\n",
    "* like_url\tbool\tDoes the token resemble a URL?*\n",
    "* like_num\tbool\tDoes the token represent a number? e.g. \"10.9\", \"10\", \"ten\", etc.\n",
    "* like_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "print([token.is_punct for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "spaCy is able make a prediction of which tag or label most likely applies in this context. We are strting to break teh text into different parts of speech - this is very powerful for analysisng text and language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubjpass X\n",
      "was VERB VBD auxpass xxx\n",
      "lost VERB VBN ROOT xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Lost VERB VBN csubj Xxxx\n",
      "on ADP IN prep xx\n",
      "the DET DT det xxx\n",
      "bypass NOUN NN compound xxxx\n",
      "road NOUN NN pobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Could VERB MD aux Xxxxx\n",
      "be VERB VB ROOT xx\n",
      "worse ADJ JJR acomp xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubjpass X\n",
      "could VERB MD aux xxxx\n",
      "be VERB VB auxpass xx\n",
      "turned VERB VBN conj xxxx\n",
      "to ADP IN aux xx\n",
      "toad NOUN NN advcl xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Wo VERB MD aux Xx\n",
      "n't ADV RB neg x'x\n",
      "you PRON PRP nsubj xxx\n",
      "take VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "back ADV RB advmod xxxx\n",
      "to ADP IN prep xx\n",
      "my ADJ PRP$ poss xx\n",
      "hometown NOUN NN pobj xxxx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Take VERB VB ROOT Xxxx\n",
      "me PRON PRP dobj xx\n",
      "back ADV RB advmod xxxx\n",
      "before ADP IN mark xxxx\n",
      "I PRON PRP nsubj X\n",
      "break VERB VBP advcl xxxx\n",
      "down PART RP prt xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubj X\n",
      "say VERB VBP ROOT xxx\n",
      "you PRON PRP nsubj xxx\n",
      "please INTJ UH intj xxxx\n",
      "return VERB VB ccomp xxxx\n",
      "me PRON PRP dobj xx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ccomp xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Just ADV RB advmod Xxxx\n",
      "like ADP IN ROOT xxxx\n",
      "Frankie PROPN NNP compound Xxxxx\n",
      "Fontaine PROPN NNP pobj Xxxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Just ADV RB advmod Xxxx\n",
      "like ADP IN prep xxxx\n",
      "Frankie PROPN NNP compound Xxxxx\n",
      "Fontaine PROPN NNP pobj Xxxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubj X\n",
      "wonder VERB VBP ROOT xxxx\n",
      "what NOUN WP dobj xxxx\n",
      "can VERB MD aux xxx\n",
      "I PRON PRP nsubj X\n",
      "do VERB VB ccomp xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubjpass X\n",
      "was VERB VBD auxpass xxx\n",
      "found VERB VBN ROOT xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Riding VERB VBG csubj Xxxxx\n",
      "a DET DT det x\n",
      "unicorn ADJ JJ dobj xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Could VERB MD aux Xxxxx\n",
      "be VERB VB ccomp xx\n",
      "worse ADJ JJR acomp xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubjpass X\n",
      "could VERB MD aux xxxx\n",
      "be VERB VB auxpass xx\n",
      "backwards ADV RB advmod xxxx\n",
      "born VERB VBN ROOT xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Wo VERB MD aux Xx\n",
      "n't ADV RB neg x'x\n",
      "you PRON PRP nsubj xxx\n",
      "take VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "back ADV RB advmod xxxx\n",
      "to ADP IN prep xx\n",
      "my ADJ PRP$ poss xx\n",
      "hometown NOUN NN pobj xxxx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Take VERB VB ROOT Xxxx\n",
      "me PRON PRP dobj xx\n",
      "back ADV RB advmod xxxx\n",
      "before ADP IN mark xxxx\n",
      "I PRON PRP nsubj X\n",
      "break VERB VBP advcl xxxx\n",
      "down PART RP prt xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Just ADV RB advmod Xxxx\n",
      "like ADP IN ROOT xxxx\n",
      "Frankie PROPN NNP compound Xxxxx\n",
      "Fontaine PROPN NNP pobj Xxxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubj X\n",
      "say VERB VBP ROOT xxx\n",
      "you PRON PRP nsubj xxx\n",
      "please INTJ UH intj xxxx\n",
      "return VERB VB ccomp xxxx\n",
      "me PRON PRP dobj xx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ccomp xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Just ADV RB advmod Xxxx\n",
      "like ADP IN ROOT xxxx\n",
      "Frankie PROPN NNP compound Xxxxx\n",
      "Fontaine PROPN NNP pobj Xxxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubj X\n",
      "wonder VERB VBP ROOT xxxx\n",
      "what NOUN WP dobj xxxx\n",
      "can VERB MD aux xxx\n",
      "I PRON PRP nsubj X\n",
      "do VERB VB ccomp xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Calm PROPN NNP ROOT Xxxx\n",
      "down PART RP prt xxxx\n",
      "and CCONJ CC cc xxx\n",
      "then ADV RB advmod xxxx\n",
      "leave VERB VB conj xxxx\n",
      "me PRON PRP dobj xx\n",
      "alone ADJ JJ oprd xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Calm PROPN NNP xcomp Xxxx\n",
      "down PART RP prt xxxx\n",
      "and CCONJ CC cc xxx\n",
      "then ADV RB advmod xxxx\n",
      "leave VERB VB conj xxxx\n",
      "me PRON PRP dobj xx\n",
      "alone ADJ JJ oprd xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Calm PROPN NNP xcomp Xxxx\n",
      "down PART RP prt xxxx\n",
      "and CCONJ CC cc xxx\n",
      "then ADV RB advmod xxxx\n",
      "leave VERB VB conj xxxx\n",
      "me PRON PRP dobj xx\n",
      "alone ADJ JJ oprd xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Calm PROPN NNP xcomp Xxxx\n",
      "down PART RP prt xxxx\n",
      "and CCONJ CC cc xxx\n",
      "then ADV RB advmod xxxx\n",
      "leave VERB VB conj xxxx\n",
      "me PRON PRP dobj xx\n",
      "alone ADJ JJ oprd xxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubj X\n",
      "say VERB VBP ROOT xxx\n",
      "you PRON PRP nsubj xxx\n",
      "please INTJ UH intj xxxx\n",
      "return VERB VB ccomp xxxx\n",
      "me PRON PRP dobj xx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Will VERB MD aux Xxxx\n",
      "you PRON PRP nsubj xxx\n",
      "ever ADV RB advmod xxxx\n",
      "return VERB VB ROOT xxxx\n",
      "me PRON PRP dobj xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Just ADV RB advmod Xxxx\n",
      "like ADP IN ROOT xxxx\n",
      "Frankie PROPN NNP compound Xxxxx\n",
      "Fontaine PROPN NNP pobj Xxxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "Just ADV RB advmod Xxxx\n",
      "like ADP IN prep xxxx\n",
      "Frankie PROPN NNP compound Xxxxx\n",
      "Fontaine PROPN NNP pobj Xxxxx\n",
      "\n",
      " SPACE   \n",
      "\n",
      "I PRON PRP nsubj X\n",
      "wonder VERB VBP ROOT xxxx\n",
      "what NOUN WP dobj xxxx\n",
      "can VERB MD aux xxx\n",
      "I PRON PRP nsubj X\n",
      "do VERB VB ccomp xx\n",
      "? PUNCT . punct ?\n",
      "\n",
      " SPACE   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_,token.shape_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "SpaCy has also performed some named entity recognition and parsing.\n",
    "\n",
    "### Named Entity Recognition (NER)\n",
    "Lets look at what spaCy has labelled as named entities - note that spaces and newlines seem to have been included here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Frankie Fontaine -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Frankie Fontaine -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Riding a -> labelled as ORG is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Frankie Fontaine -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Frankie Fontaine -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Calm -> labelled as NORP is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Calm -> labelled as NORP is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Calm -> labelled as NORP is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Frankie Fontaine -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text Frankie Fontaine -> labelled as PERSON is a space? False\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n",
      "Text \n",
      " -> labelled as GPE is a space? True\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(\"Text {} -> labelled as {} is a space? {}\".format(ent.text,ent.label_, ent.text==\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the SpaCy model, we can now start to process the test is an appropriate manner for our needs. Fpor example, for sentiment analysis we may need to look at sentance structure and meaning, and so we will need the parsing information and punctuation. For statistical models we will want to remove any potential noise like punctuation and stopwords. For example, to remove stop words we could:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I lost \n",
      " Lost bypass road \n",
      " Could worse \n",
      " I turned toad \n",
      " Wo n't hometown ? \n",
      " Take I break \n",
      " I return \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " Just like Frankie Fontaine \n",
      " I wonder I ? \n",
      " I found \n",
      " Riding unicorn \n",
      " Could worse \n",
      " I backwards born \n",
      " Wo n't hometown ? \n",
      " Take I break \n",
      " Will return ? \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " I return \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " I wonder I ? \n",
      " Calm leave \n",
      " Calm leave \n",
      " Calm leave \n",
      " Calm leave \n",
      " I return \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " Just like Frankie Fontaine \n",
      " I wonder I ? \n",
      " \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Note that this function returns a Doc only and strips away any ner - so do this before applying ner!\n",
    "\n",
    "\"\"\"\n",
    "def remove_stopwords(doc):\n",
    "    token_pos = [None] \n",
    "    [token_pos.append(t.i) for t in doc if t.is_stop != False]        \n",
    "    doc = Doc(doc.vocab, words=[t.text for i, t in enumerate(doc) if i not in token_pos])\n",
    "    return doc\n",
    "\n",
    "print(remove_stopwords(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I lost \n",
      " Lost bypass road \n",
      " Could worse \n",
      " I turned toad \n",
      " Wo n't hometown ? \n",
      " Take I break \n",
      " I return \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " Just like Frankie Fontaine \n",
      " I wonder I ? \n",
      " I found \n",
      " Riding unicorn \n",
      " Could worse \n",
      " I backwards born \n",
      " Wo n't hometown ? \n",
      " Take I break \n",
      " Will return ? \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " I return \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " I wonder I ? \n",
      " Calm leave \n",
      " Calm leave \n",
      " Calm leave \n",
      " Calm leave \n",
      " I return \n",
      " Will return ? \n",
      " Will return ? \n",
      " Just like Frankie Fontaine \n",
      " Just like Frankie Fontaine \n",
      " I wonder I ? \n",
      " \n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(doc):\n",
    "    token_pos = [None] \n",
    "    [token_pos.append(t.i) for t in doc if t.is_stop != False]        \n",
    "    doc2 = Doc(doc.vocab, words=[t.text for i, t in enumerate(doc) if i not in token_pos])\n",
    "    #doc2.ents = [e for i, e in enumerate(doc.ents) if i not in token_pos]\n",
    "    return doc2\n",
    "\n",
    "d = remove_stopwords(doc)\n",
    "print(d)\n",
    "\n",
    "#NOte that there are no ents on this - just a pure doc. So run NER after this to get NER values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get over the issue that spaCy is classifying whitespaces and newlines as named entities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Frankie Fontaine -> labelled as PERSON\n",
      "Text Frankie Fontaine -> labelled as PERSON\n",
      "Text Riding a -> labelled as ORG\n",
      "Text Frankie Fontaine -> labelled as PERSON\n",
      "Text Frankie Fontaine -> labelled as PERSON\n",
      "Text Calm -> labelled as NORP\n",
      "Text Calm -> labelled as NORP\n",
      "Text Calm -> labelled as NORP\n",
      "Text Frankie Fontaine -> labelled as PERSON\n",
      "Text Frankie Fontaine -> labelled as PERSON\n"
     ]
    }
   ],
   "source": [
    "def remove_whitespace_entities(doc):\n",
    "    doc.ents = [ent for ent in doc.ents if (ent.text != ' ') and (ent.text != '\\n')  ]\n",
    "    return doc\n",
    "\n",
    "\n",
    "doc = remove_whitespace_entities(doc)\n",
    "for ent in doc.ents:\n",
    "    print(\"Text {} -> labelled as {}\".format(ent.text,ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the parsing\n",
    "It is possible to visualise the parsing on using ```displaCy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1800\" height=\"487.0\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Wo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">take</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">me</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">back</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">my</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">hometown?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,354.0 L1618.0,342.0 1602.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "sentence_spans = list(doc.sents)\n",
    "displacy.render(sentence_spans[2], style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Just like Frankie Fontaine</br>Just like Frankie Fontaine</br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(sentence_spans[6], style='ent', jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
