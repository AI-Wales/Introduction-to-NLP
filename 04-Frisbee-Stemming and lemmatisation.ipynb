{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing words to their  Stemming and Lemmatisation\n",
    "\n",
    "So far we have tidied up our text and split it into smaller chunks and removed any frequent joining words. Now we have to start digging into the nature of language and words a little more. One task is to reduce words down to a more basic form, e.g., waiting, waited and waits can be reduced to wait.\n",
    "\n",
    "This is where things get interesting - and tricky!\n",
    "\n",
    "\n",
    "### What is the difference? \n",
    "Lets take the example of **Stemming** - the process of reducing inflected (or sometimes derived) words to their word *stem*, base or root form. For example argue, argued, argues, arguing reduce to the stem argu. Usually stemming is a crude heuristic process that chops off the ends of words in the hope of achieving the root correctly most of the time. \n",
    "\n",
    "**Lemmatisation** aims to do this using vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the *lemma*. \n",
    "\n",
    "If confronted with the token 'saw', stemming might return just 's', whereas lemmatization would attempt to return either 'see' or 'saw' depending on whether the use of the token was as a verb or a noun. \n",
    "\n",
    "\n",
    "### Implementing \n",
    "Now we could start to build our own functions here, using rules such as\n",
    "\n",
    "* if the word ends in 'ed', remove the 'ed'\n",
    "\n",
    "* if the word ends in 'ing', remove the 'ing'\n",
    "\n",
    "* if the word ends in 'ly', remove the 'ly'\n",
    "\n",
    "This might work for stemming but lemmatising is a far more complex challenge. \n",
    "\n",
    "But there is good news - someone has already done all the hard work for us!\n",
    "\n",
    "Using existing libraries like [**nltk**](https://www.nltk.org) we can perform stemming and lemmatising quickly and easily.\n",
    "\n",
    "Guess what - they can also be used to tokenise your text too! Lets see how we might use NLTK for this:\n",
    "\n",
    "## Stemming with nltk\n",
    "\n",
    "Nltk has a number of stemming algorithms but Porter (PorterStemer) is the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game\n",
      "game\n",
      "game\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "words = [\"game\",\"gaming\",\"gamed\",\"games\"]\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "for word in words:\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/pughd/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "game\n",
      "gaming\n",
      "gamed\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "for word in words:\n",
    "    print(lemmatiser.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a larger body of text - using nltk to tokenise\n",
    "\n",
    "Lets use nltk to tokenise before we apply the lemtatisation and stemming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_o = \"\"\"\n",
    "Locked in a sorry dream\n",
    "You know we're drowning in designer ice creams\n",
    "I scream, this is the present but it's no surprise\n",
    "Then I realize\n",
    "What I see I spies\n",
    "(Nice to see you, to see you, to see you)\n",
    "The past was eagle-eyed\n",
    "(To see you, nice to see you, to see you, to see you)\n",
    "The future's pixelised\n",
    "(To see you, nice to see you, to see you, to see you, to see you)\n",
    "I had my Frisbee sharpened and honed\n",
    "I had it galvanized and chromed\n",
    "Decapitate and bury your toys\n",
    "My Frisbee brings the noise\n",
    "What I see I spies\n",
    "(Nice to see you, to see you, to see you)\n",
    "The past was eagle-eyed\n",
    "(To see you, nice to see you, to see you, to see you)\n",
    "The future's pixelised\n",
    "(To see you, nice to see you, to see you, to see you, to see you)\n",
    "To see you, to see you, to see you, nice to see you\n",
    "(Wipe your windscreen with a chocolate cake)\n",
    "To see you, to see you, to see you, nice to see you\n",
    "(Count your pizzas before they bake)\n",
    "To see you, to see you, to see you, nice to see you\n",
    "(Wipe your windscreen with a chocolate cake)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pughd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Locked \t -> Lemma: Locked \t -> stem: lock\n",
      "in \t -> Lemma: in \t -> stem: in\n",
      "a \t -> Lemma: a \t -> stem: a\n",
      "sorry \t -> Lemma: sorry \t -> stem: sorri\n",
      "dream \t -> Lemma: dream \t -> stem: dream\n",
      "You \t -> Lemma: You \t -> stem: you\n",
      "know \t -> Lemma: know \t -> stem: know\n",
      "we \t -> Lemma: we \t -> stem: we\n",
      "'re \t -> Lemma: 're \t -> stem: 're\n",
      "drowning \t -> Lemma: drowning \t -> stem: drown\n",
      "in \t -> Lemma: in \t -> stem: in\n",
      "designer \t -> Lemma: designer \t -> stem: design\n",
      "ice \t -> Lemma: ice \t -> stem: ice\n",
      "creams \t -> Lemma: cream \t -> stem: cream\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "scream \t -> Lemma: scream \t -> stem: scream\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "this \t -> Lemma: this \t -> stem: thi\n",
      "is \t -> Lemma: is \t -> stem: is\n",
      "the \t -> Lemma: the \t -> stem: the\n",
      "present \t -> Lemma: present \t -> stem: present\n",
      "but \t -> Lemma: but \t -> stem: but\n",
      "it \t -> Lemma: it \t -> stem: it\n",
      "'s \t -> Lemma: 's \t -> stem: 's\n",
      "no \t -> Lemma: no \t -> stem: no\n",
      "surprise \t -> Lemma: surprise \t -> stem: surpris\n",
      "Then \t -> Lemma: Then \t -> stem: then\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "realize \t -> Lemma: realize \t -> stem: realiz\n",
      "What \t -> Lemma: What \t -> stem: what\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "spies \t -> Lemma: spy \t -> stem: spi\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "Nice \t -> Lemma: Nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "The \t -> Lemma: The \t -> stem: the\n",
      "past \t -> Lemma: past \t -> stem: past\n",
      "was \t -> Lemma: wa \t -> stem: wa\n",
      "eagle-eyed \t -> Lemma: eagle-eyed \t -> stem: eagle-ey\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "To \t -> Lemma: To \t -> stem: To\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "nice \t -> Lemma: nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "The \t -> Lemma: The \t -> stem: the\n",
      "future \t -> Lemma: future \t -> stem: futur\n",
      "'s \t -> Lemma: 's \t -> stem: 's\n",
      "pixelised \t -> Lemma: pixelised \t -> stem: pixelis\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "To \t -> Lemma: To \t -> stem: To\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "nice \t -> Lemma: nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "had \t -> Lemma: had \t -> stem: had\n",
      "my \t -> Lemma: my \t -> stem: my\n",
      "Frisbee \t -> Lemma: Frisbee \t -> stem: frisbe\n",
      "sharpened \t -> Lemma: sharpened \t -> stem: sharpen\n",
      "and \t -> Lemma: and \t -> stem: and\n",
      "honed \t -> Lemma: honed \t -> stem: hone\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "had \t -> Lemma: had \t -> stem: had\n",
      "it \t -> Lemma: it \t -> stem: it\n",
      "galvanized \t -> Lemma: galvanized \t -> stem: galvan\n",
      "and \t -> Lemma: and \t -> stem: and\n",
      "chromed \t -> Lemma: chromed \t -> stem: chrome\n",
      "Decapitate \t -> Lemma: Decapitate \t -> stem: decapit\n",
      "and \t -> Lemma: and \t -> stem: and\n",
      "bury \t -> Lemma: bury \t -> stem: buri\n",
      "your \t -> Lemma: your \t -> stem: your\n",
      "toys \t -> Lemma: toy \t -> stem: toy\n",
      "My \t -> Lemma: My \t -> stem: My\n",
      "Frisbee \t -> Lemma: Frisbee \t -> stem: frisbe\n",
      "brings \t -> Lemma: brings \t -> stem: bring\n",
      "the \t -> Lemma: the \t -> stem: the\n",
      "noise \t -> Lemma: noise \t -> stem: nois\n",
      "What \t -> Lemma: What \t -> stem: what\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "I \t -> Lemma: I \t -> stem: I\n",
      "spies \t -> Lemma: spy \t -> stem: spi\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "Nice \t -> Lemma: Nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "The \t -> Lemma: The \t -> stem: the\n",
      "past \t -> Lemma: past \t -> stem: past\n",
      "was \t -> Lemma: wa \t -> stem: wa\n",
      "eagle-eyed \t -> Lemma: eagle-eyed \t -> stem: eagle-ey\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "To \t -> Lemma: To \t -> stem: To\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "nice \t -> Lemma: nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "The \t -> Lemma: The \t -> stem: the\n",
      "future \t -> Lemma: future \t -> stem: futur\n",
      "'s \t -> Lemma: 's \t -> stem: 's\n",
      "pixelised \t -> Lemma: pixelised \t -> stem: pixelis\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "To \t -> Lemma: To \t -> stem: To\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "nice \t -> Lemma: nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "To \t -> Lemma: To \t -> stem: To\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "nice \t -> Lemma: nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "Wipe \t -> Lemma: Wipe \t -> stem: wipe\n",
      "your \t -> Lemma: your \t -> stem: your\n",
      "windscreen \t -> Lemma: windscreen \t -> stem: windscreen\n",
      "with \t -> Lemma: with \t -> stem: with\n",
      "a \t -> Lemma: a \t -> stem: a\n",
      "chocolate \t -> Lemma: chocolate \t -> stem: chocol\n",
      "cake \t -> Lemma: cake \t -> stem: cake\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "To \t -> Lemma: To \t -> stem: To\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "nice \t -> Lemma: nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "Count \t -> Lemma: Count \t -> stem: count\n",
      "your \t -> Lemma: your \t -> stem: your\n",
      "pizzas \t -> Lemma: pizza \t -> stem: pizza\n",
      "before \t -> Lemma: before \t -> stem: befor\n",
      "they \t -> Lemma: they \t -> stem: they\n",
      "bake \t -> Lemma: bake \t -> stem: bake\n",
      ") \t -> Lemma: ) \t -> stem: )\n",
      "To \t -> Lemma: To \t -> stem: To\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      ", \t -> Lemma: , \t -> stem: ,\n",
      "nice \t -> Lemma: nice \t -> stem: nice\n",
      "to \t -> Lemma: to \t -> stem: to\n",
      "see \t -> Lemma: see \t -> stem: see\n",
      "you \t -> Lemma: you \t -> stem: you\n",
      "( \t -> Lemma: ( \t -> stem: (\n",
      "Wipe \t -> Lemma: Wipe \t -> stem: wipe\n",
      "your \t -> Lemma: your \t -> stem: your\n",
      "windscreen \t -> Lemma: windscreen \t -> stem: windscreen\n",
      "with \t -> Lemma: with \t -> stem: with\n",
      "a \t -> Lemma: a \t -> stem: a\n",
      "chocolate \t -> Lemma: chocolate \t -> stem: chocol\n",
      "cake \t -> Lemma: cake \t -> stem: cake\n",
      ") \t -> Lemma: ) \t -> stem: )\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#tokensise the text\n",
    "tokens = word_tokenize(text_o)\n",
    "\n",
    "for token in tokens:\n",
    "    print(\"{} \\t -> Lemma: {} \\t -> stem: {}\".format(token, lemmatiser.lemmatize(token), stemmer.stem(token)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What other preprocessing would be useful here? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - POS with nltk\n",
    "The **part of speech (POS)** explains how a word is used in a sentence. There are eight main parts of speech - nouns, pronouns, adjectives, verbs, adverbs, prepositions, conjunctions and interjections. Want to know more - [read here](https://medium.com/greyatom/learning-pos-tagging-chunking-in-nlp-85f7f811a8cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/pughd/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[('Locked', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('sorry', 'JJ'), ('dream', 'NN'), ('You', 'PRP'), ('know', 'VBP'), ('we', 'PRP'), (\"'re\", 'VBP'), ('drowning', 'VBG'), ('in', 'IN'), ('designer', 'NN'), ('ice', 'NN'), ('creams', 'NNS'), ('I', 'PRP'), ('scream', 'VBP'), (',', ','), ('this', 'DT'), ('is', 'VBZ'), ('the', 'DT'), ('present', 'JJ'), ('but', 'CC'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('no', 'DT'), ('surprise', 'NN'), ('Then', 'RB'), ('I', 'PRP'), ('realize', 'VBP'), ('What', 'WP'), ('I', 'PRP'), ('see', 'VBP'), ('I', 'PRP'), ('spies', 'NNS'), ('(', '('), ('Nice', 'NNP'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (')', ')'), ('The', 'DT'), ('past', 'NN'), ('was', 'VBD'), ('eagle-eyed', 'JJ'), ('(', '('), ('To', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('nice', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (')', ')'), ('The', 'DT'), ('future', 'NN'), (\"'s\", 'POS'), ('pixelised', 'VBN'), ('(', '('), ('To', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('nice', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (')', ')'), ('I', 'PRP'), ('had', 'VBD'), ('my', 'PRP$'), ('Frisbee', 'NNP'), ('sharpened', 'VBD'), ('and', 'CC'), ('honed', 'VBD'), ('I', 'PRP'), ('had', 'VBD'), ('it', 'PRP'), ('galvanized', 'VBD'), ('and', 'CC'), ('chromed', 'VBD'), ('Decapitate', 'NNP'), ('and', 'CC'), ('bury', 'VB'), ('your', 'PRP$'), ('toys', 'NNS'), ('My', 'PRP$'), ('Frisbee', 'NNP'), ('brings', 'VBZ'), ('the', 'DT'), ('noise', 'NN'), ('What', 'WP'), ('I', 'PRP'), ('see', 'VBP'), ('I', 'PRP'), ('spies', 'NNS'), ('(', '('), ('Nice', 'NNP'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (')', ')'), ('The', 'DT'), ('past', 'NN'), ('was', 'VBD'), ('eagle-eyed', 'JJ'), ('(', '('), ('To', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('nice', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (')', ')'), ('The', 'DT'), ('future', 'NN'), (\"'s\", 'POS'), ('pixelised', 'VBN'), ('(', '('), ('To', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('nice', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (')', ')'), ('To', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('nice', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), ('(', '('), ('Wipe', 'VB'), ('your', 'PRP$'), ('windscreen', 'NN'), ('with', 'IN'), ('a', 'DT'), ('chocolate', 'NN'), ('cake', 'NN'), (')', ')'), ('To', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('nice', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), ('(', '('), ('Count', 'VB'), ('your', 'PRP$'), ('pizzas', 'NN'), ('before', 'IN'), ('they', 'PRP'), ('bake', 'VBP'), (')', ')'), ('To', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), (',', ','), ('nice', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('you', 'PRP'), ('(', '('), ('Wipe', 'VB'), ('your', 'PRP$'), ('windscreen', 'NN'), ('with', 'IN'), ('a', 'DT'), ('chocolate', 'NN'), ('cake', 'NN'), (')', ')')]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "\n",
    "tokens_pos = pos_tag(tokens)\n",
    "\n",
    "print(tokens_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
