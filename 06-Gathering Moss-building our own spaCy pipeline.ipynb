{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Developing our own spaCy pipeline\n",
    "\n",
    "The basic spaCy model comes with a default pipeline - it performs a series of processing tasks in sequence to give us an output. We can alter and customise that pipeline for our own needs. Different text and different applications will require different text processing - it is rare that the default will do everything we want (or may do too much!)\n",
    "\n",
    "For example, if you do not intend to use Part of Speech tagging or Named Entity Recognition you can remove these from the pipeline - would could save processing time and power for large bodies of text. Or you may want to automatically remove stop-words when you apply the spaCy model. Lets look at how we can build this.  \n",
    "\n",
    "\n",
    "Before you start make sure you have installed spaCy and the en model:\n",
    "\n",
    "\n",
    "```\n",
    "conda install -c conda-forge spacy\n",
    "python -m spacy download en\n",
    "```\n",
    "\n",
    "\n",
    "See the [spaCy](https://spacy.io) documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Lost capacity\n",
    "For infinity\n",
    "You and me are idly\n",
    "Gathering moss\n",
    "Fields of industry\n",
    "Death by misery\n",
    "You and I are idly\n",
    "You and me are idly\n",
    "Gathering moss\n",
    "False security\n",
    "Faked insanity\n",
    "You and I united by\n",
    "Itemised bills\n",
    "Kills my sympathy\n",
    "Builds my agony\n",
    "You and me are idly\n",
    "You and I are idly\n",
    "Gathering moss\n",
    "But when you see me\n",
    "I'll be idly sweeping\n",
    "The dust away\n",
    "(Dust away)\n",
    "Look here comes the shore again\n",
    "And we'll aim there to be merry\n",
    "You and I are idly\n",
    "You and I are idly\n",
    "You and me\n",
    "Gathering moss\n",
    "You and me\n",
    "Gathering moss\n",
    "You and me are idly\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Pipelines\n",
    "\n",
    "When we apply the spaCy model using `nlp(text)`, spaCy is actually applying several processing steps in series. Each process is applied in turn and the output sent to the next process. This is termed a processing pipeline. \n",
    "\n",
    "Instead of applying functions after applying the spaCy model, we can also add them to the default spaCy pipeline. In this way we can develop our own custom spaCy pipelines for our needs. This is a really cool and tidy way of processing our text.\n",
    "\n",
    "Lets explore this - lets start by loading the default model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nlp_default = spacy.load('en')\n",
    "nlp_custom = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### The default pipeline\n",
    "We can view what the default pipeline is by calling `pipeline`. We can see that by default spaCy applies a tagger, a dependency parser and then a named entity recogniser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x1225af0f0>),\n ('parser', <spacy.pipeline.DependencyParser at 0x1225a2888>),\n ('ner', <spacy.pipeline.EntityRecognizer at 0x1225a27d8>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_custom.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can remove any process that we don't want or add in any others that we do. \n",
    "\n",
    "Removing unneeded components can speed up performance especially on very large bodies of text. For example, if we only intend to do statistical analysis and do not need dependency parsing we can remove it from the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Customising the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "You can remove any process that we don't want that can be time consuming but aren't required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x1225b5400>),\n ('ner', <spacy.pipeline.EntityRecognizer at 0x1225a2af0>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_custom.remove_pipe('parser')\n",
    "nlp_custom.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can also add our own functions to the pipeline.\n",
    "\n",
    "**NB:** run the function to remove stop-words *before* you run the NER so that we perform the NER on the reduced body of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Example custom functions that work with the spaCy doc.\n",
    "\"\"\"\n",
    "Note that this function returns a Doc only and strips away any NER - so do this before applying NER!\n",
    "\"\"\"\n",
    "def remove_stopwords(doc):\n",
    "    token_pos = [None] \n",
    "    [token_pos.append(t.i) for t in doc if t.is_stop != False]        \n",
    "    doc = Doc(doc.vocab, words=[t.text for i, t in enumerate(doc) if i not in token_pos])\n",
    "    return doc\n",
    "\n",
    "def remove_whitespace_entities(doc):\n",
    "    doc.ents = [ent for ent in doc.ents if (ent.text != ' ') and (ent.text != '\\n')  ]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x1225b5400>),\n ('rem_stpw', <function __main__.remove_stopwords(doc)>),\n ('ner', <spacy.pipeline.EntityRecognizer at 0x1225a2af0>),\n ('rem_ws_ent', <function __main__.remove_whitespace_entities(doc)>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_custom.add_pipe(remove_stopwords, name='rem_stpw', after = 'tagger')\n",
    "nlp_custom.add_pipe(remove_whitespace_entities, name='rem_ws_ent', after = 'ner')\n",
    "\n",
    "nlp_custom.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Applying the spaCy model now also removes stop-words and whitespace from the entities as part of its automatic processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lost capacity\n",
      "For infinity\n",
      "You and me are idly\n",
      "Gathering moss\n",
      "Fields of industry\n",
      "Death by misery\n",
      "You and I are idly\n",
      "You and me are idly\n",
      "Gathering moss\n",
      "False security\n",
      "Faked insanity\n",
      "You and I united by\n",
      "Itemised bills\n",
      "Kills my sympathy\n",
      "Builds my agony\n",
      "You and me are idly\n",
      "You and I are idly\n",
      "Gathering moss\n",
      "But when you see me\n",
      "I'll be idly sweeping\n",
      "The dust away\n",
      "(Dust away)\n",
      "Look here comes the shore again\n",
      "And we'll aim there to be merry\n",
      "You and I are idly\n",
      "You and I are idly\n",
      "You and me\n",
      "Gathering moss\n",
      "You and me\n",
      "Gathering moss\n",
      "You and me are idly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_default(text)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lost capacity \n",
      " For infinity \n",
      " You idly \n",
      " Gathering moss \n",
      " Fields industry \n",
      " Death misery \n",
      " You I idly \n",
      " You idly \n",
      " Gathering moss \n",
      " False security \n",
      " Faked insanity \n",
      " You I united \n",
      " Itemised bills \n",
      " Kills sympathy \n",
      " Builds agony \n",
      " You idly \n",
      " You I idly \n",
      " Gathering moss \n",
      " But \n",
      " I 'll idly sweeping \n",
      " The dust away \n",
      " ( Dust away ) \n",
      " Look comes shore \n",
      " And 'll aim merry \n",
      " You I idly \n",
      " You I idly \n",
      " You \n",
      " Gathering moss \n",
      " You \n",
      " Gathering moss \n",
      " You idly \n",
      " \n"
     ]
    }
   ],
   "source": [
    "doc_pp = nlp_custom(text)\n",
    "print(doc_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Gathering moss \n",
      " Fields industry \n",
      " Death misery \n",
      " You I idly, Gathering moss \n",
      " False, Kills, Builds, Gathering, \n",
      " You \n",
      " Gathering moss)\n"
     ]
    }
   ],
   "source": [
    "print(doc_pp.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### This can be saved and used in the future for common text preprocessing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "06-Gathering Moss-building our own spaCy pipeline.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
